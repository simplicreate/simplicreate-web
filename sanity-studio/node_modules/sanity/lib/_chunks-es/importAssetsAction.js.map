{"version":3,"file":"importAssetsAction.js","sources":["../../src/_internal/cli/actions/media/lib/findNdjsonEntry.ts","../../src/_internal/cli/actions/media/importAssetsAction.ts"],"sourcesContent":["import readline from 'node:readline'\nimport {Readable} from 'node:stream'\n\n/**\n * Find the first matching entry in the provided NDJSON stream.\n *\n * @internal\n */\nexport async function* findNdjsonEntry<Type>(\n  ndjson: Readable,\n  matcher: (line: Type) => boolean,\n): AsyncGenerator<Type | undefined> {\n  const lines = readline.createInterface({\n    input: ndjson,\n  })\n\n  try {\n    for await (const line of lines) {\n      const parsed = JSON.parse(line.trim())\n      if (matcher(parsed)) {\n        yield parsed\n        return\n      }\n    }\n\n    yield undefined\n  } finally {\n    lines.close()\n    // Explicitly destroy the underlying stream to prevent file descriptor leaks\n    ndjson.destroy()\n  }\n}\n\n/**\n * Read and parse all entries from an NDJSON stream.\n *\n * @internal\n */\nexport async function readNdjsonFile<Type>(ndjson: Readable): Promise<Type[]> {\n  const lines = readline.createInterface({\n    input: ndjson,\n  })\n\n  const entries: Type[] = []\n\n  try {\n    for await (const line of lines) {\n      const trimmed = line.trim()\n      if (trimmed) {\n        entries.push(JSON.parse(trimmed))\n      }\n    }\n  } finally {\n    lines.close()\n    // Explicitly destroy the underlying stream to prevent file descriptor leaks\n    ndjson.destroy()\n  }\n\n  return entries\n}\n","import {createHash} from 'node:crypto'\nimport {createReadStream} from 'node:fs'\nimport fs, {mkdtemp} from 'node:fs/promises'\nimport {tmpdir} from 'node:os'\nimport path from 'node:path'\nimport {text} from 'node:stream/consumers'\nimport {pipeline} from 'node:stream/promises'\n\nimport {\n  type CliCommandAction,\n  type CliCommandContext,\n  type CliOutputter,\n  type SanityClient,\n} from '@sanity/cli'\nimport {type FileAsset, type ImageAsset, type SanityDocument} from '@sanity/types'\nimport {type Chalk} from 'chalk'\nimport gunzipMaybe from 'gunzip-maybe'\nimport isTar from 'is-tar'\n// @ts-expect-error `peek-stream` module currently untyped\nimport peek from 'peek-stream'\nimport {\n  catchError,\n  EMPTY,\n  filter,\n  from,\n  map,\n  mergeMap,\n  mergeWith,\n  type Observable,\n  of,\n  type OperatorFunction,\n  pipe,\n  scan,\n  switchMap,\n  tap,\n  zip,\n} from 'rxjs'\nimport tar from 'tar-fs'\nimport {glob} from 'tinyglobby'\n\nimport {debug as baseDebug} from '../../debug'\nimport {MINIMUM_API_VERSION} from './constants'\nimport {determineTargetMediaLibrary} from './lib/determineTargetMediaLibrary'\nimport {readNdjsonFile} from './lib/findNdjsonEntry'\n\ninterface ImportAssetsFlags {\n  'media-library-id'?: string\n  'replace-aspects'?: boolean\n}\n\nconst debug = baseDebug.extend('importMedia')\n\nconst DEFAULT_CONCURRENCY = 6\n\ninterface MediaLibraryUploadResult {\n  asset: SanityDocument & {\n    _type: 'sanity.asset'\n    assetType: ImageAsset['_type'] | FileAsset['_type']\n    aspects: unknown\n  }\n  assetInstance: ImageAsset | FileAsset\n}\n\ninterface MediaLibraryUploadResponse {\n  type: 'response'\n  body: MediaLibraryUploadResult\n}\n\ninterface ResolvedAsset {\n  /**\n   * The ids of the `sanity.asset` documents that currently refer to the asset.\n   *\n   * These documents contain aspects, and reference an asset instance document.\n   */\n  assetIds: string[]\n  /**\n   * The original filename of the asset as it appears in the import source.\n   *\n   * Note: Currently includes `images/` or `files/` prefix.\n   */\n  originalFilename: string\n  sha1Hash: string\n  isExistingAsset: boolean\n}\n\n/**\n * @internal\n */\nexport type AssetWithAspects<Asset extends ResolvedAsset = ResolvedAsset> = Asset & {\n  aspects: unknown | undefined\n}\n\ninterface State {\n  /**\n   * The count of input files.\n   */\n  fileCount: number\n  /**\n   * The last asset processed.\n   */\n  asset: AssetWithAspects\n}\n\ninterface Options {\n  sourcePath: string\n  client: SanityClient\n  replaceAspects: boolean\n  chalk: Chalk\n  spinner: ReturnType<CliCommandContext['output']['spinner']>\n  output: CliOutputter\n}\n\ninterface AspectDataEntry {\n  filename: string\n  aspects?: unknown\n}\n\ninterface Context extends Options {\n  workingPath: string\n  aspectsData: AspectDataEntry[]\n}\n\n// TODO: Order assets lexicographically before processing, allow resumable import\n// TODO: Granularly report upload progress of each asset (especially useful for large assets).\nconst importAssetsAction: CliCommandAction<ImportAssetsFlags> = async (args, context) => {\n  const {output, apiClient, chalk} = context\n  const [importSourcePath] = args.argsWithoutOptions\n  const replaceAspects = args.extOptions['replace-aspects'] ?? false\n\n  const mediaLibraryId =\n    args.extOptions['media-library-id'] ?? (await determineTargetMediaLibrary(context))\n\n  const client = apiClient().withConfig({\n    apiVersion: MINIMUM_API_VERSION,\n    requestTagPrefix: 'sanity.mediaLibraryCli.import',\n    resource: {\n      type: 'media-library',\n      id: mediaLibraryId,\n    },\n    perspective: 'drafts',\n  })\n\n  output.print()\n  output.print(`Importing to media library: ${chalk.bold(mediaLibraryId)}`)\n  output.print(`Importing from path: ${chalk.bold(importSourcePath)}`)\n  output.print()\n\n  const spinner = output.spinner('Beginning importâ€¦').start()\n\n  importer({\n    client,\n    sourcePath: importSourcePath,\n    replaceAspects,\n    chalk,\n    spinner,\n    output,\n  })\n    .pipe(\n      reportResult({\n        chalk,\n        spinner,\n      }),\n    )\n    .subscribe({\n      error: (error) => {\n        spinner.stop()\n        output.error(error)\n      },\n    })\n}\n\nexport default importAssetsAction\n\nexport function importer(options: Options): Observable<State> {\n  return resolveSource(options).pipe(\n    mergeMap(({files, images, aspectsNdjsonPath, workingPath}) => {\n      const fileCount = files.length + images.length\n\n      if (fileCount === 0) {\n        throw new Error('No assets to import')\n      }\n\n      // Read the ndjson file once upfront and cache the data to avoid creating\n      // multiple read streams (which causes file descriptor leaks)\n      const aspectsDataPromise = aspectsNdjsonPath\n        ? readNdjsonFile<AspectDataEntry>(createReadStream(aspectsNdjsonPath))\n        : Promise.resolve([])\n\n      return from(aspectsDataPromise).pipe(\n        mergeMap((aspectsData) => {\n          const context: Context = {\n            ...options,\n            workingPath,\n            aspectsData,\n          }\n\n          return from(files).pipe(\n            switchMap((file) => zip(of<'file'>('file'), of(file))),\n            mergeWith(from(images).pipe(switchMap((file) => zip(of<'image'>('image'), of(file))))),\n            fetchExistingAssets(context),\n            uploadAsset(context),\n            resolveAspectData(context),\n            setAspects(context),\n            map((asset) => ({\n              asset,\n              fileCount,\n            })),\n          )\n        }),\n      )\n    }),\n  )\n}\n\n/**\n * @internal\n */\nexport function resolveSource({\n  sourcePath,\n  chalk,\n}: Pick<Context, 'sourcePath' | 'chalk'>): Observable<{\n  files: string[]\n  images: string[]\n  aspectsNdjsonPath: string\n  workingPath: string\n}> {\n  return from(fs.stat(sourcePath)).pipe(\n    switchMap((stats) => {\n      return stats.isDirectory()\n        ? of(sourcePath)\n        : from(mkdtemp(path.join(tmpdir(), 'sanity-media-library-import'))).pipe(\n            switchMap((tempPath) => {\n              return from(\n                pipeline(createReadStream(sourcePath), gunzipMaybe(), untarMaybe(tempPath)),\n              ).pipe(map(() => tempPath))\n            }),\n          )\n    }),\n    switchMap((importSourcePath) => {\n      return from(\n        glob(['**/data.ndjson'], {\n          cwd: importSourcePath,\n          deep: 2,\n          absolute: true,\n        }),\n      ).pipe(\n        map(([aspectsNdjsonPath]) => ({\n          aspectsNdjsonPath,\n          importSourcePath,\n          workingPath:\n            typeof aspectsNdjsonPath === 'undefined'\n              ? importSourcePath\n              : path.dirname(aspectsNdjsonPath),\n        })),\n      )\n    }),\n    tap(({aspectsNdjsonPath, importSourcePath}) => {\n      if (typeof aspectsNdjsonPath === 'undefined') {\n        debug(\n          `[No data.ndjson file] No predefined aspect data will be imported from ${importSourcePath}`,\n        )\n      } else {\n        debug(`[Found NDJSON file] ${aspectsNdjsonPath}`)\n      }\n    }),\n    switchMap(({aspectsNdjsonPath, workingPath}) => {\n      return from(\n        Promise.all([\n          glob(['files/*'], {\n            cwd: workingPath,\n          }),\n          glob(['images/*'], {\n            cwd: workingPath,\n          }),\n        ]),\n      ).pipe(\n        map(([files, images]) => ({\n          files,\n          images,\n          aspectsNdjsonPath,\n          workingPath,\n        })),\n      )\n    }),\n  )\n}\n\n/**\n * Untar the stream if its contents appear to be tarred.\n *\n * @internal\n */\nfunction untarMaybe(outputPath: string) {\n  // @ts-expect-error `peek-stream` module currently untyped\n  return peek({newline: false, maxBuffer: 300}, (data, swap) => {\n    if (isTar(data)) {\n      return swap(null, tar.extract(outputPath))\n    }\n\n    return swap(null)\n  })\n}\n\n/**\n * Fetch the ids of all asset documents that reference the input asset.\n * The input asset is identified by its SHA-1 hash.\n *\n * @internal\n */\nfunction fetchAssetsByHash({\n  client,\n  type,\n}: {\n  client: SanityClient\n  type: 'image' | 'file'\n}): OperatorFunction<string, [hash: string, assetIds: string[]]> {\n  return switchMap((hash) =>\n    client.observable\n      .fetch<string[]>(\n        `*[\n          _type == \"sanity.asset\" &&\n          currentVersion._ref == *[\n            _type == $type &&\n            sha1hash == $hash\n          ][0]._id\n        ]._id`,\n        {\n          type: ['sanity', `${type}Asset`].join('.'),\n          hash,\n        },\n        {\n          tag: 'asset.getId',\n        },\n      )\n      .pipe(switchMap((assetIds) => zip(of(hash), of(assetIds)))),\n  )\n}\n\nfunction fetchExistingAssets({\n  client,\n  workingPath,\n}: Context): OperatorFunction<\n  [type: 'image' | 'file', asset: string],\n  ResolvedAsset | [type: 'image' | 'file', asset: string, hash: string]\n> {\n  return mergeMap(([type, asset]) => {\n    const createSha1Hash = createHash('sha1')\n\n    const sha1hash = text(\n      createReadStream(path.join(workingPath, asset)).pipe(createSha1Hash).setEncoding('hex'),\n    )\n\n    return from(sha1hash).pipe(\n      tap((hash) => debug(`[Asset ${asset}] Checking for ${type} asset with hash ${hash}`)),\n      fetchAssetsByHash({client, type}),\n      map<\n        [string, string[]],\n        ResolvedAsset | [type: 'image' | 'file', asset: string, hash: string]\n      >(([hash, assetIds]) => {\n        if (assetIds.length === 0) {\n          return [type, asset, hash]\n        }\n\n        return {\n          originalFilename: asset,\n          sha1Hash: hash,\n          assetIds,\n          isExistingAsset: true,\n        }\n      }),\n    )\n  })\n}\n\n/**\n * Find the matching entry in the cached aspect data and attach it to the asset object.\n *\n * @internal\n */\nfunction resolveAspectData({\n  aspectsData,\n}: Context): OperatorFunction<ResolvedAsset, AssetWithAspects> {\n  return map((resolvedAsset) => {\n    // If no aspects data exists, return asset with undefined aspects\n    if (!aspectsData || aspectsData.length === 0) {\n      return {\n        ...resolvedAsset,\n        aspects: undefined,\n      }\n    }\n\n    // Find matching aspect data from the cached data\n    const aspectsFromImport = aspectsData.find(\n      (entry) => entry.filename === resolvedAsset.originalFilename,\n    )\n\n    return {\n      ...resolvedAsset,\n      aspects: aspectsFromImport?.aspects,\n    }\n  })\n}\n\n// TODO: Batch mutations to reduce HTTP request count.\nexport function setAspects({\n  client,\n  replaceAspects,\n}: Pick<Context, 'client' | 'replaceAspects'>): OperatorFunction<\n  AssetWithAspects,\n  AssetWithAspects\n> {\n  return mergeMap((asset) => {\n    const {assetIds, isExistingAsset, aspects} = asset\n\n    if (isExistingAsset && !replaceAspects) {\n      debug(`[Asset ${asset.originalFilename}] Skipping replacement of existing aspects`)\n      return of(asset)\n    }\n\n    if (typeof aspects === 'undefined') {\n      debug(`[Asset ${asset.originalFilename}] No aspects to import`)\n      return of(asset)\n    }\n\n    const transaction = assetIds.reduce(\n      (previous, assetId) => previous.patch(assetId, {set: {aspects}}),\n      client.observable.transaction(),\n    )\n\n    debug(\n      `[Asset ${asset.originalFilename}] Setting aspects on asset documents ${JSON.stringify(assetIds)}`,\n    )\n\n    return transaction\n      .commit({\n        visibility: 'async',\n        tag: 'asset.setAspects',\n      })\n      .pipe(map(() => asset))\n  }, DEFAULT_CONCURRENCY)\n}\n\nfunction uploadAsset({\n  workingPath,\n  client,\n}: Context): OperatorFunction<\n  ResolvedAsset | [type: 'image' | 'file', asset: string, hash: string],\n  ResolvedAsset\n> {\n  return mergeMap((maybeResolvedAsset) => {\n    if ('assetIds' in maybeResolvedAsset) {\n      debug(\n        `[Asset ${maybeResolvedAsset.originalFilename}] Skipping upload of existing asset with hash ${maybeResolvedAsset.sha1Hash}`,\n      )\n      return of(maybeResolvedAsset)\n    }\n\n    const [type, asset, hash] = maybeResolvedAsset\n    debug(`[Asset ${asset}] Uploading new asset`)\n\n    return client.observable.assets\n      .upload(type, createReadStream(path.join(workingPath, asset)), {\n        tag: 'asset.upload',\n      })\n      .pipe(\n        catchError((error) => {\n          // An asset matching the hash was not found during previous steps, but appears to exist upon upload.\n          //\n          // This may occur if:\n          //   - The asset was uploaded by another client since the check was performed.\n          //   - The asset instance document exists, but is not referenced by any asset document.\n          if (error.statusCode === 409) {\n            debug(`[Asset ${asset}] Cannot overwrite existing ${type} asset with hash ${hash}`)\n            return EMPTY\n          }\n          return EMPTY\n        }),\n        filter((response) => response.type === 'response'),\n        tap(() => debug(`[Asset ${asset}] Finished uploading new asset`)),\n        // TODO: The `client.assets.upload` method should return `MediaLibraryUploadResponse` when operating on Media Library resources. When that occurs, this type assertion can be removed.\n        map((response) => (response as unknown as MediaLibraryUploadResponse).body),\n        map<MediaLibraryUploadResult, ResolvedAsset>((result) => ({\n          assetIds: [result.asset._id],\n          originalFilename: asset,\n          sha1Hash: hash,\n          isExistingAsset: false,\n        })),\n      )\n  }, DEFAULT_CONCURRENCY)\n}\n\nfunction reportResult({\n  chalk,\n  spinner,\n}: Pick<Context, 'chalk' | 'spinner'>): OperatorFunction<State, [number, State | undefined]> {\n  let previousState: State | undefined\n\n  return pipe(\n    scan<State, [number, State | undefined]>(\n      (processedAssetsCount, state) => [processedAssetsCount[0] + 1, state],\n      [0, undefined],\n    ),\n    tap({\n      next: ([processedAssetsCount, state]) => {\n        previousState = state\n        spinner.text = `${processedAssetsCount} of ${state?.fileCount} assets imported ${chalk.dim(state?.asset.originalFilename)}`\n      },\n      complete: () => spinner.succeed(`Imported ${previousState?.fileCount} assets`),\n    }),\n  )\n}\n"],"names":["readNdjsonFile","ndjson","lines","readline","createInterface","input","entries","line","trimmed","trim","push","JSON","parse","close","destroy","debug","baseDebug","extend","DEFAULT_CONCURRENCY","importAssetsAction","args","context","output","apiClient","chalk","importSourcePath","argsWithoutOptions","replaceAspects","extOptions","mediaLibraryId","determineTargetMediaLibrary","client","withConfig","apiVersion","MINIMUM_API_VERSION","requestTagPrefix","resource","type","id","perspective","print","bold","spinner","start","importer","sourcePath","pipe","reportResult","subscribe","error","stop","options","resolveSource","mergeMap","files","images","aspectsNdjsonPath","workingPath","fileCount","length","Error","aspectsDataPromise","createReadStream","Promise","resolve","from","aspectsData","switchMap","file","zip","of","mergeWith","fetchExistingAssets","uploadAsset","resolveAspectData","setAspects","map","asset","fs","stat","stats","isDirectory","mkdtemp","path","join","tmpdir","tempPath","pipeline","gunzipMaybe","untarMaybe","glob","cwd","deep","absolute","dirname","tap","all","outputPath","peek","newline","maxBuffer","data","swap","isTar","tar","extract","fetchAssetsByHash","hash","observable","fetch","tag","assetIds","createSha1Hash","createHash","sha1hash","text","setEncoding","originalFilename","sha1Hash","isExistingAsset","resolvedAsset","aspects","undefined","aspectsFromImport","find","entry","filename","transaction","reduce","previous","assetId","patch","set","stringify","commit","visibility","maybeResolvedAsset","assets","upload","catchError","statusCode","EMPTY","filter","response","body","result","_id","previousState","scan","processedAssetsCount","state","next","dim","complete","succeed"],"mappings":";;;;;;;;;;;;;;;;AAsCA,eAAsBA,eAAqBC,QAAmC;AAC5E,QAAMC,QAAQC,SAASC,gBAAgB;AAAA,IACrCC,OAAOJ;AAAAA,EAAAA,CACR,GAEKK,UAAkB,CAAA;AAExB,MAAI;AACF,qBAAiBC,QAAQL,OAAO;AAC9B,YAAMM,UAAUD,KAAKE,KAAAA;AACjBD,iBACFF,QAAQI,KAAKC,KAAKC,MAAMJ,OAAO,CAAC;AAAA,IAEpC;AAAA,EACF,UAAA;AACEN,UAAMW,MAAAA,GAENZ,OAAOa,QAAAA;AAAAA,EACT;AAEA,SAAOR;AACT;ACTA,MAAMS,QAAQC,QAAUC,OAAO,aAAa,GAEtCC,sBAAsB,GAwEtBC,qBAA0D,OAAOC,MAAMC,YAAY;AACvF,QAAM;AAAA,IAACC;AAAAA,IAAQC;AAAAA,IAAWC;AAAAA,EAAAA,IAASH,SAC7B,CAACI,gBAAgB,IAAIL,KAAKM,oBAC1BC,iBAAiBP,KAAKQ,WAAW,iBAAiB,KAAK,IAEvDC,iBACJT,KAAKQ,WAAW,kBAAkB,KAAM,MAAME,4BAA4BT,OAAO,GAE7EU,SAASR,UAAAA,EAAYS,WAAW;AAAA,IACpCC,YAAYC;AAAAA,IACZC,kBAAkB;AAAA,IAClBC,UAAU;AAAA,MACRC,MAAM;AAAA,MACNC,IAAIT;AAAAA,IAAAA;AAAAA,IAENU,aAAa;AAAA,EAAA,CACd;AAEDjB,SAAOkB,SACPlB,OAAOkB,MAAM,+BAA+BhB,MAAMiB,KAAKZ,cAAc,CAAC,EAAE,GACxEP,OAAOkB,MAAM,wBAAwBhB,MAAMiB,KAAKhB,gBAAgB,CAAC,EAAE,GACnEH,OAAOkB,MAAAA;AAEP,QAAME,UAAUpB,OAAOoB,QAAQ,wBAAmB,EAAEC,MAAAA;AAEpDC,WAAS;AAAA,IACPb;AAAAA,IACAc,YAAYpB;AAAAA,IACZE;AAAAA,IACAH;AAAAA,IACAkB;AAAAA,IACApB;AAAAA,EAAAA,CACD,EACEwB,KACCC,aAAa;AAAA,IACXvB;AAAAA,IACAkB;AAAAA,EAAAA,CACD,CACH,EACCM,UAAU;AAAA,IACTC,OAAQA,CAAAA,UAAU;AAChBP,cAAQQ,KAAAA,GACR5B,OAAO2B,MAAMA,KAAK;AAAA,IACpB;AAAA,EAAA,CACD;AACL;AAIO,SAASL,SAASO,SAAqC;AAC5D,SAAOC,cAAcD,OAAO,EAAEL,KAC5BO,SAAS,CAAC;AAAA,IAACC;AAAAA,IAAOC;AAAAA,IAAQC;AAAAA,IAAmBC;AAAAA,EAAAA,MAAiB;AAC5D,UAAMC,YAAYJ,MAAMK,SAASJ,OAAOI;AAExC,QAAID,cAAc;AAChB,YAAM,IAAIE,MAAM,qBAAqB;AAKvC,UAAMC,qBAAqBL,oBACvBxD,eAAgC8D,iBAAiBN,iBAAiB,CAAC,IACnEO,QAAQC,QAAQ,EAAE;AAEtB,WAAOC,KAAKJ,kBAAkB,EAAEf,KAC9BO,SAAUa,CAAAA,gBAAgB;AACxB,YAAM7C,UAAmB;AAAA,QACvB,GAAG8B;AAAAA,QACHM;AAAAA,QACAS;AAAAA,MAAAA;AAGF,aAAOD,KAAKX,KAAK,EAAER,KACjBqB,UAAWC,CAAAA,SAASC,IAAIC,GAAW,MAAM,GAAGA,GAAGF,IAAI,CAAC,CAAC,GACrDG,UAAUN,KAAKV,MAAM,EAAET,KAAKqB,UAAWC,CAAAA,SAASC,IAAIC,GAAY,OAAO,GAAGA,GAAGF,IAAI,CAAC,CAAC,CAAC,CAAC,GACrFI,oBAAoBnD,OAAO,GAC3BoD,YAAYpD,OAAO,GACnBqD,kBAAkBrD,OAAO,GACzBsD,WAAWtD,OAAO,GAClBuD,IAAKC,CAAAA,WAAW;AAAA,QACdA;AAAAA,QACAnB;AAAAA,MAAAA,EACA,CACJ;AAAA,IACF,CAAC,CACH;AAAA,EACF,CAAC,CACH;AACF;AAKO,SAASN,cAAc;AAAA,EAC5BP;AAAAA,EACArB;AACqC,GAKpC;AACD,SAAOyC,KAAKa,GAAGC,KAAKlC,UAAU,CAAC,EAAEC,KAC/BqB,UAAWa,CAAAA,UACFA,MAAMC,YAAAA,IACTX,GAAGzB,UAAU,IACboB,KAAKiB,QAAQC,KAAKC,KAAKC,UAAU,6BAA6B,CAAC,CAAC,EAAEvC,KAChEqB,UAAWmB,cACFrB,KACLsB,SAASzB,iBAAiBjB,UAAU,GAAG2C,YAAAA,GAAeC,WAAWH,QAAQ,CAAC,CAC5E,EAAExC,KAAK8B,IAAI,MAAMU,QAAQ,CAAC,CAC3B,CACH,CACL,GACDnB,UAAW1C,CAAAA,qBACFwC,KACLyB,KAAK,CAAC,gBAAgB,GAAG;AAAA,IACvBC,KAAKlE;AAAAA,IACLmE,MAAM;AAAA,IACNC,UAAU;AAAA,EAAA,CACX,CACH,EAAE/C,KACA8B,IAAI,CAAC,CAACpB,iBAAiB,OAAO;AAAA,IAC5BA;AAAAA,IACA/B;AAAAA,IACAgC,aACE,OAAOD,oBAAsB,MACzB/B,mBACA0D,KAAKW,QAAQtC,iBAAiB;AAAA,EAAA,EACpC,CACJ,CACD,GACDuC,IAAI,CAAC;AAAA,IAACvC;AAAAA,IAAmB/B;AAAAA,EAAAA,MAAsB;AAE3CV,UADE,OAAOyC,oBAAsB,MAE7B,yEAAyE/B,gBAAgB,KAGrF,uBAAuB+B,iBAAiB,EAF9C;AAAA,EAIJ,CAAC,GACDW,UAAU,CAAC;AAAA,IAACX;AAAAA,IAAmBC;AAAAA,EAAAA,MACtBQ,KACLF,QAAQiC,IAAI,CACVN,KAAK,CAAC,SAAS,GAAG;AAAA,IAChBC,KAAKlC;AAAAA,EAAAA,CACN,GACDiC,KAAK,CAAC,UAAU,GAAG;AAAA,IACjBC,KAAKlC;AAAAA,EAAAA,CACN,CAAC,CACH,CACH,EAAEX,KACA8B,IAAI,CAAC,CAACtB,OAAOC,MAAM,OAAO;AAAA,IACxBD;AAAAA,IACAC;AAAAA,IACAC;AAAAA,IACAC;AAAAA,EAAAA,EACA,CACJ,CACD,CACH;AACF;AAOA,SAASgC,WAAWQ,YAAoB;AAEtC,SAAOC,KAAK;AAAA,IAACC,SAAS;AAAA,IAAOC,WAAW;AAAA,EAAA,GAAM,CAACC,MAAMC,SAC/CC,MAAMF,IAAI,IACLC,KAAK,MAAME,IAAIC,QAAQR,UAAU,CAAC,IAGpCK,KAAK,IAAI,CACjB;AACH;AAQA,SAASI,kBAAkB;AAAA,EACzB3E;AAAAA,EACAM;AAIF,GAAiE;AAC/D,SAAO8B,UAAWwC,CAAAA,SAChB5E,OAAO6E,WACJC,MACC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAOA;AAAA,IACExE,MAAM,CAAC,UAAU,GAAGA,IAAI,OAAO,EAAE+C,KAAK,GAAG;AAAA,IACzCuB;AAAAA,EAAAA,GAEF;AAAA,IACEG,KAAK;AAAA,EAAA,CAET,EACChE,KAAKqB,UAAW4C,cAAa1C,IAAIC,GAAGqC,IAAI,GAAGrC,GAAGyC,QAAQ,CAAC,CAAC,CAAC,CAC9D;AACF;AAEA,SAASvC,oBAAoB;AAAA,EAC3BzC;AAAAA,EACA0B;AACO,GAGP;AACA,SAAOJ,SAAS,CAAC,CAAChB,MAAMwC,KAAK,MAAM;AACjC,UAAMmC,iBAAiBC,WAAW,MAAM,GAElCC,WAAWC,KACfrD,iBAAiBqB,KAAKC,KAAK3B,aAAaoB,KAAK,CAAC,EAAE/B,KAAKkE,cAAc,EAAEI,YAAY,KAAK,CACxF;AAEA,WAAOnD,KAAKiD,QAAQ,EAAEpE,KACpBiD,IAAKY,UAAS5F,MAAM,UAAU8D,KAAK,kBAAkBxC,IAAI,oBAAoBsE,IAAI,EAAE,CAAC,GACpFD,kBAAkB;AAAA,MAAC3E;AAAAA,MAAQM;AAAAA,IAAAA,CAAK,GAChCuC,IAGE,CAAC,CAAC+B,MAAMI,QAAQ,MACZA,SAASpD,WAAW,IACf,CAACtB,MAAMwC,OAAO8B,IAAI,IAGpB;AAAA,MACLU,kBAAkBxC;AAAAA,MAClByC,UAAUX;AAAAA,MACVI;AAAAA,MACAQ,iBAAiB;AAAA,IAAA,CAEpB,CACH;AAAA,EACF,CAAC;AACH;AAOA,SAAS7C,kBAAkB;AAAA,EACzBR;AACO,GAAsD;AAC7D,SAAOU,IAAK4C,CAAAA,kBAAkB;AAE5B,QAAI,CAACtD,eAAeA,YAAYP,WAAW;AACzC,aAAO;AAAA,QACL,GAAG6D;AAAAA,QACHC,SAASC;AAAAA,MAAAA;AAKb,UAAMC,oBAAoBzD,YAAY0D,KACnCC,WAAUA,MAAMC,aAAaN,cAAcH,gBAC9C;AAEA,WAAO;AAAA,MACL,GAAGG;AAAAA,MACHC,SAASE,mBAAmBF;AAAAA,IAAAA;AAAAA,EAEhC,CAAC;AACH;AAGO,SAAS9C,WAAW;AAAA,EACzB5C;AAAAA,EACAJ;AAC0C,GAG1C;AACA,SAAO0B,SAAUwB,CAAAA,UAAU;AACzB,UAAM;AAAA,MAACkC;AAAAA,MAAUQ;AAAAA,MAAiBE;AAAAA,IAAAA,IAAW5C;AAE7C,QAAI0C,mBAAmB,CAAC5F;AACtBZ,aAAAA,MAAM,UAAU8D,MAAMwC,gBAAgB,4CAA4C,GAC3E/C,GAAGO,KAAK;AAGjB,QAAI,OAAO4C,UAAY;AACrB1G,aAAAA,MAAM,UAAU8D,MAAMwC,gBAAgB,wBAAwB,GACvD/C,GAAGO,KAAK;AAGjB,UAAMkD,cAAchB,SAASiB,OAC3B,CAACC,UAAUC,YAAYD,SAASE,MAAMD,SAAS;AAAA,MAACE,KAAK;AAAA,QAACX;AAAAA,MAAAA;AAAAA,IAAO,CAAE,GAC/D1F,OAAO6E,WAAWmB,aACpB;AAEAhH,WAAAA,MACE,UAAU8D,MAAMwC,gBAAgB,wCAAwC1G,KAAK0H,UAAUtB,QAAQ,CAAC,EAClG,GAEOgB,YACJO,OAAO;AAAA,MACNC,YAAY;AAAA,MACZzB,KAAK;AAAA,IAAA,CACN,EACAhE,KAAK8B,IAAI,MAAMC,KAAK,CAAC;AAAA,EAC1B,GAAG3D,mBAAmB;AACxB;AAEA,SAASuD,YAAY;AAAA,EACnBhB;AAAAA,EACA1B;AACO,GAGP;AACA,SAAOsB,SAAUmF,CAAAA,uBAAuB;AACtC,QAAI,cAAcA;AAChBzH,aAAAA,MACE,UAAUyH,mBAAmBnB,gBAAgB,iDAAiDmB,mBAAmBlB,QAAQ,EAC3H,GACOhD,GAAGkE,kBAAkB;AAG9B,UAAM,CAACnG,MAAMwC,OAAO8B,IAAI,IAAI6B;AAC5BzH,WAAAA,MAAM,UAAU8D,KAAK,uBAAuB,GAErC9C,OAAO6E,WAAW6B,OACtBC,OAAOrG,MAAMyB,iBAAiBqB,KAAKC,KAAK3B,aAAaoB,KAAK,CAAC,GAAG;AAAA,MAC7DiC,KAAK;AAAA,IAAA,CACN,EACAhE;AAAAA,MACC6F,WAAY1F,CAAAA,UAMNA,MAAM2F,eAAe,OACvB7H,MAAM,UAAU8D,KAAK,+BAA+BxC,IAAI,oBAAoBsE,IAAI,EAAE,GAC3EkC,SAEFA,KACR;AAAA,MACDC,OAAQC,CAAAA,aAAaA,SAAS1G,SAAS,UAAU;AAAA,MACjD0D,IAAI,MAAMhF,MAAM,UAAU8D,KAAK,gCAAgC,CAAC;AAAA;AAAA,MAEhED,IAAKmE,CAAAA,aAAcA,SAAmDC,IAAI;AAAA,MAC1EpE,IAA8CqE,CAAAA,YAAY;AAAA,QACxDlC,UAAU,CAACkC,OAAOpE,MAAMqE,GAAG;AAAA,QAC3B7B,kBAAkBxC;AAAAA,QAClByC,UAAUX;AAAAA,QACVY,iBAAiB;AAAA,MAAA,EACjB;AAAA,IAAA;AAAA,EAER,GAAGrG,mBAAmB;AACxB;AAEA,SAAS6B,aAAa;AAAA,EACpBvB;AAAAA,EACAkB;AACkC,GAAyD;AAC3F,MAAIyG;AAEJ,SAAOrG,KACLsG,KACE,CAACC,sBAAsBC,UAAU,CAACD,qBAAqB,CAAC,IAAI,GAAGC,KAAK,GACpE,CAAC,GAAG5B,MAAS,CACf,GACA3B,IAAI;AAAA,IACFwD,MAAMA,CAAC,CAACF,sBAAsBC,KAAK,MAAM;AACvCH,sBAAgBG,OAChB5G,QAAQyE,OAAO,GAAGkC,oBAAoB,OAAOC,OAAO5F,SAAS,oBAAoBlC,MAAMgI,IAAIF,OAAOzE,MAAMwC,gBAAgB,CAAC;AAAA,IAC3H;AAAA,IACAoC,UAAUA,MAAM/G,QAAQgH,QAAQ,YAAYP,eAAezF,SAAS,SAAS;AAAA,EAAA,CAC9E,CACH;AACF;"}